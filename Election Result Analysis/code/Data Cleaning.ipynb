{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4fba3f",
   "metadata": {},
   "source": [
    "### Import Necessary Packages and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73719463",
   "metadata": {},
   "source": [
    "##### We start by importing pandas and numpy for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11dc43c9-0bf1-49a8-aa1f-67fedc994bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6dba2",
   "metadata": {},
   "source": [
    "##### Here we're reading in all the csvs we used as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bde39c58-e94e-4b05-b9ff-74328ec8e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/countypres_2000-2024.csv\")\n",
    "unemployment = pd.read_excel(\"https://raw.github.com/jamilditter/election_results/refs/heads/main/data/LAUS_Annual_Unemployment_By_State_2000to2024.xlsx\", skiprows=3)\n",
    "med_income = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/Median_Household_Income_By_State_FRED.csv\")\n",
    "age = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/State_by_Age.csv\")\n",
    "education = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/State_Education_by_Degree.csv\")\n",
    "population = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/Population%20by%20Age%20and%20Sex%20-%20US%2C%20States%2C%20Counties.csv\")\n",
    "bach_2024 = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/FRED_BachelorsEduAttainment2024.csv\")\n",
    "alaska_med_income = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/MEHOINUSAKA646N.csv\")\n",
    "rhode_is_med_income = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/MEHOINUSRIA672N_new.csv\")\n",
    "voter_participation = pd.read_csv(\"https://raw.githubusercontent.com/jamilditter/election_results/refs/heads/main/data/voter_participation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f3656",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199aab5a",
   "metadata": {},
   "source": [
    "##### After reading in all our csvs, we will start to prepare each dataset for a final merge. To do this, we're going to isolate the data we want, and sort them by year and state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439893a",
   "metadata": {},
   "source": [
    "#### Votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e04ff",
   "metadata": {},
   "source": [
    "##### Here, we start by totalling the votes by state and year for the total number of votes, the total number of Democrat votes, and the total number of Republican votes. After this, we melt the dataframe so we can get a single column for each type of vote, indexed against the year and state from which those votes came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629f171b-6e82-4923-ad50-c89aa75a4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes[\"totalvotes\"] = votes.groupby([\"state\", \"year\"])[\"candidatevotes\"].transform(\"sum\")\n",
    "votes[\"dem\"] = votes[votes[\"party\"] == \"DEMOCRAT\"].groupby([\"state\", \"year\"])[\"candidatevotes\"].transform(\"sum\")\n",
    "votes[\"rep\"] = votes[votes[\"party\"] == \"REPUBLICAN\"].groupby([\"state\", \"year\"])[\"candidatevotes\"].transform(\"sum\")\n",
    "\n",
    "totalvotes_melted = pd.melt(\n",
    "    votes, id_vars = [\"state\", \"year\"],\n",
    "    value_vars = [\"totalvotes\"],\n",
    "    var_name = \"party\",\n",
    "    value_name = \"total_votes\"\n",
    ").drop_duplicates().dropna().drop(columns=[\"party\"])\n",
    "\n",
    "demvotes_melted = pd.melt(\n",
    "    votes, id_vars = [\"state\", \"year\"],\n",
    "    value_vars = [\"dem\"],\n",
    "    var_name = \"party\",\n",
    "    value_name = \"dem_votes\"\n",
    ").drop_duplicates().dropna().drop(columns=[\"party\"])\n",
    "\n",
    "repvotes_melted = pd.melt(\n",
    "    votes, id_vars = [\"state\", \"year\"],\n",
    "    value_vars = [\"rep\"],\n",
    "    var_name = \"party\",\n",
    "    value_name = \"rep_votes\"\n",
    ").drop_duplicates().dropna().drop(columns=[\"party\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b7e01a",
   "metadata": {},
   "source": [
    "#### Unemployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208fecf",
   "metadata": {},
   "source": [
    "##### Here, we start by creating a dictionary to rename the Series IDs to states so we can merge them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7f7f5c0-aefc-4cbd-abea-36b1a2f331f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_states = {\n",
    "    'LAUST010000000000003': 'Alabama',\n",
    "    'LAUST020000000000003': 'Alaska',\n",
    "    'LAUST040000000000003': 'Arizona',\n",
    "    'LAUST050000000000003': 'Arkansas',\n",
    "    'LAUST060000000000003': 'California',\n",
    "    'LAUST080000000000003': 'Colorado',\n",
    "    'LAUST090000000000003': 'Connecticut',\n",
    "    'LAUST100000000000003': 'Delaware',\n",
    "    'LAUST110000000000003': 'District of Columbia',\n",
    "    'LAUST120000000000003': 'Florida',\n",
    "    'LAUST130000000000003': 'Georgia',\n",
    "    'LAUST150000000000003': 'Hawaii',\n",
    "    'LAUST160000000000003': 'Idaho',\n",
    "    'LAUST170000000000003': 'Illinois',\n",
    "    'LAUST180000000000003': 'Indiana',\n",
    "    'LAUST190000000000003': 'Iowa',\n",
    "    'LAUST200000000000003': 'Kansas',\n",
    "    'LAUST210000000000003': 'Kentucky',\n",
    "    'LAUST220000000000003': 'Louisiana',\n",
    "    'LAUST230000000000003': 'Maine',\n",
    "    'LAUST240000000000003': 'Maryland',\n",
    "    'LAUST250000000000003': 'Massachusetts',\n",
    "    'LAUST260000000000003': 'Michigan',\n",
    "    'LAUST270000000000003': 'Minnesota',\n",
    "    'LAUST280000000000003': 'Mississippi',\n",
    "    'LAUST290000000000003': 'Missouri',\n",
    "    'LAUST300000000000003': 'Montana',\n",
    "    'LAUST310000000000003': 'Nebraska',\n",
    "    'LAUST320000000000003': 'Nevada',\n",
    "    'LAUST330000000000003': 'New Hampshire',\n",
    "    'LAUST340000000000003': 'New Jersey',\n",
    "    'LAUST350000000000003': 'New Mexico',\n",
    "    'LAUST360000000000003': 'New York',\n",
    "    'LAUST370000000000003': 'North Carolina',\n",
    "    'LAUST380000000000003': 'North Dakota',\n",
    "    'LAUST390000000000003': 'Ohio',\n",
    "    'LAUST400000000000003': 'Oklahoma',\n",
    "    'LAUST410000000000003': 'Oregon',\n",
    "    'LAUST420000000000003': 'Pennsylvania',\n",
    "    'LAUST440000000000003': 'Rhode Island',\n",
    "    'LAUST450000000000003': 'South Carolina',\n",
    "    'LAUST460000000000003': 'South Dakota',\n",
    "    'LAUST470000000000003': 'Tennessee',\n",
    "    'LAUST480000000000003': 'Texas',\n",
    "    'LAUST490000000000003': 'Utah',\n",
    "    'LAUST500000000000003': 'Vermont',\n",
    "    'LAUST510000000000003': 'Virginia',\n",
    "    'LAUST530000000000003': 'Washington',\n",
    "    'LAUST540000000000003': 'West Virginia',\n",
    "    'LAUST550000000000003': 'Wisconsin',\n",
    "    'LAUST560000000000003': 'Wyoming'\n",
    "}\n",
    "\n",
    "unemployment[\"Series ID\"] = unemployment[\"Series ID\"].replace(rename_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf02ee5d",
   "metadata": {},
   "source": [
    "##### We then remove \"Annual\\n\" from the year columns so we can isolate the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "630f6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_renamed = unemployment.rename(columns = lambda x: x[-4:]).rename(columns={\"s ID\": \"state\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c0c79",
   "metadata": {},
   "source": [
    "##### Finally, we melt the dataframe to create an unemployment column indexed against state and year, matching our previous votes dataframe. We then filter the dataframe to only include the years we have voter information for (2000, 2004, 2008, 2012, 2016, 2020, 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab09ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_melted = pd.melt(\n",
    "    unemployment_renamed, id_vars = [\"state\"],\n",
    "    value_vars = [\"2000\", \"2004\", \"2008\", \"2012\", \"2016\", \"2020\", \"2024\"],\n",
    "    var_name = \"year\",\n",
    "    value_name = \"unemployment_rate\"\n",
    ")\n",
    "\n",
    "election_years = [\"2000\", \"2004\", \"2008\", \"2012\", \"2016\", \"2020\", \"2024\"]\n",
    "unemployment_melted = unemployment_melted[unemployment_melted[\"year\"].isin(election_years)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9e62d",
   "metadata": {},
   "source": [
    "#### Median Income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78c96b",
   "metadata": {},
   "source": [
    "##### Again we start by creating a dictionary to transform the state abbreviations into the full names of the states, so they match the other dataframes. We also convert the to just show the year, to keep it consistent between dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c86b84e9-f369-42de-be24-7bac05d5d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\jamil\\Temp\\ipykernel_20964\\4086705710.py:55: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  med_income[\"observation_date\"] = pd.to_datetime(med_income[\"observation_date\"]).dt.year\n"
     ]
    }
   ],
   "source": [
    "abbr_to_state = {\n",
    "    \"ALA\": \"Alabama\",\n",
    "    \"AKA\": \"Alaska\",\n",
    "    \"ARA\": \"Arkansas\",\n",
    "    \"AZA\": \"Arizona\",\n",
    "    \"CAA\": \"California\",\n",
    "    \"COA\": \"Colorado\",\n",
    "    \"CTA\": \"Connecticut\",\n",
    "    \"DCA\": \"District of Columbia\",\n",
    "    \"DEA\": \"Delaware\",\n",
    "    \"FLA\": \"Florida\",\n",
    "    \"GAA\": \"Georgia\",\n",
    "    \"HIA\": \"Hawaii\",\n",
    "    \"IDA\": \"Idaho\",\n",
    "    \"ILA\": \"Illinois\",\n",
    "    \"INA\": \"Indiana\",\n",
    "    \"IAA\": \"Iowa\",\n",
    "    \"KSA\": \"Kansas\",\n",
    "    \"KYA\": \"Kentucky\",\n",
    "    \"LAA\": \"Louisiana\", \n",
    "    \"MEA\": \"Maine\",\n",
    "    \"MDA\": \"Maryland\",\n",
    "    \"MAA\": \"Massachusetts\",\n",
    "    \"MIA\": \"Michigan\",\n",
    "    \"MNA\": \"Minnesota\",\n",
    "    \"MSA\": \"Mississippi\",\n",
    "    \"MOA\": \"Missouri\",\n",
    "    \"MTA\": \"Montana\",\n",
    "    \"NEA\": \"Nebraska\",\n",
    "    \"NVA\": \"Nevada\",\n",
    "    \"NHA\": \"New Hampshire\",\n",
    "    \"NJA\": \"New Jersey\",\n",
    "    \"NMA\": \"New Mexico\",\n",
    "    \"NYA\": \"New York\",\n",
    "    \"NCA\": \"North Carolina\",\n",
    "    \"NDA\": \"North Dakota\",\n",
    "    \"OHA\": \"Ohio\",\n",
    "    \"OKA\": \"Oklahoma\",\n",
    "    \"ORA\": \"Oregon\",\n",
    "    \"PAA\": \"Pennsylvania\",\n",
    "    \"RIA\": \"Rhode Island\",\n",
    "    \"SCA\": \"South Carolina\",\n",
    "    \"SDA\": \"South Dakota\",\n",
    "    \"TNA\": \"Tennessee\",\n",
    "    \"TXA\": \"Texas\",\n",
    "    \"UTA\": \"Utah\",\n",
    "    \"VAA\": \"Virginia\",\n",
    "    \"VTA\": \"Vermont\",\n",
    "    \"WAA\": \"Washington\",\n",
    "    \"WIA\": \"Wisconsin\",\n",
    "    \"WVA\": \"West Virginia\",\n",
    "    \"WYA\": \"Wyoming\"\n",
    "}\n",
    "\n",
    "med_income[\"observation_date\"] = pd.to_datetime(med_income[\"observation_date\"]).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a9d30",
   "metadata": {},
   "source": [
    "##### Our intial dataset was missing both Alaska and Rhode Island median incomes, so we downloaded this data separately, and have to merge it into the main dataframe. To do this, we need to convert the observation date columns into years, so they match up with the main median income dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "442b1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "alaska_med_income[\"observation_date\"] = pd.to_datetime(alaska_med_income[\"observation_date\"]).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25da05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhode_is_med_income[\"observation_date\"] = pd.to_datetime(rhode_is_med_income[\"observation_date\"]).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e7a82",
   "metadata": {},
   "source": [
    "##### After adjusting this, we can merge everything together, then rename the observation date column to year, so it matches the other dataframes we will need to merge it together with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fabc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_income_merged = pd.merge(alaska_med_income, med_income)\n",
    "med_income_merged = pd.merge(rhode_is_med_income, med_income_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af251d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_income_renamed = med_income_merged.rename(columns={\"observation_date\": \"year\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763543dc",
   "metadata": {},
   "source": [
    "##### Finally, we melt the dataframe, creating a single column for median income, indexed against state and year. And for the last step, we filter the dataframe to only include the election years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dfd10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_income_melted = pd.melt(\n",
    "    med_income_renamed, id_vars = [\"year\"],\n",
    "    value_vars = ['MEHOINUSALA672N', 'MEHOINUSAKA646N', 'MEHOINUSARA672N', 'MEHOINUSAZA672N', 'MEHOINUSCAA672N', \n",
    "                  'MEHOINUSCOA672N', 'MEHOINUSCTA672N', 'MEHOINUSDCA672N', 'MEHOINUSDEA672N', 'MEHOINUSFLA672N', \n",
    "                  'MEHOINUSGAA672N', 'MEHOINUSHIA672N', 'MEHOINUSIAA672N', 'MEHOINUSIDA672N', 'MEHOINUSILA672N', \n",
    "                  'MEHOINUSINA672N', 'MEHOINUSKSA672N', 'MEHOINUSKYA672N', 'MEHOINUSLAA672N', 'MEHOINUSMAA672N', \n",
    "                  'MEHOINUSMDA672N', 'MEHOINUSMEA672N', 'MEHOINUSMIA672N', 'MEHOINUSMNA672N', 'MEHOINUSMOA672N', \n",
    "                  'MEHOINUSMSA672N', 'MEHOINUSMTA672N', 'MEHOINUSNEA672N', 'MEHOINUSNCA672N', 'MEHOINUSNDA672N', \n",
    "                  'MEHOINUSNHA672N', 'MEHOINUSNJA672N', 'MEHOINUSNMA672N', 'MEHOINUSNVA672N', 'MEHOINUSNYA672N', \n",
    "                  'MEHOINUSOHA672N', 'MEHOINUSOKA672N', 'MEHOINUSORA672N', 'MEHOINUSPAA672N', 'MEHOINUSSCA672N', \n",
    "                  'MEHOINUSSDA672N', 'MEHOINUSTNA672N', 'MEHOINUSTXA672N', 'MEHOINUSUTA672N', 'MEHOINUSVAA672N', \n",
    "                  'MEHOINUSVTA672N', 'MEHOINUSWAA672N', 'MEHOINUSWIA672N', 'MEHOINUSWVA672N', 'MEHOINUSWYA672N',\n",
    "                  'MEHOINUSRIA672N'],\n",
    "    var_name = \"state\",\n",
    "    value_name = \"median_income\"\n",
    ")\n",
    "\n",
    "med_income_melted[\"state\"] = med_income_melted[\"state\"].str[8:11].map(abbr_to_state)\n",
    "med_income_melted[\"year\"] = med_income_melted[\"year\"].astype(str)\n",
    "\n",
    "med_income_melted = med_income_melted[med_income_melted[\"year\"].isin(election_years)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6a340",
   "metadata": {},
   "source": [
    "#### Median Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94102a39",
   "metadata": {},
   "source": [
    "##### We create a dictionary to convert the fips codes to state names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "327ddabe-5ee8-4de9-bced-70fc85e3cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_states = {\n",
    "    1: \"Alabama\",\n",
    "    2: \"Alaska\",\n",
    "    4: \"Arizona\",\n",
    "    5: \"Arkansas\",\n",
    "    6: \"California\",\n",
    "    8: \"Colorado\",\n",
    "    9: \"Connecticut\",\n",
    "    10: \"Delaware\",\n",
    "    11: \"District of Columbia\",\n",
    "    12: \"Florida\",\n",
    "    13: \"Georgia\",\n",
    "    15: \"Hawaii\",\n",
    "    16: \"Idaho\",\n",
    "    17: \"Illinois\",\n",
    "    18: \"Indiana\",\n",
    "    19: \"Iowa\",\n",
    "    20: \"Kansas\",\n",
    "    21: \"Kentucky\",\n",
    "    22: \"Louisiana\",\n",
    "    23: \"Maine\",\n",
    "    24: \"Maryland\",\n",
    "    25: \"Massachusetts\",\n",
    "    26: \"Michigan\",\n",
    "    27: \"Minnesota\",\n",
    "    28: \"Mississippi\",\n",
    "    29: \"Missouri\",\n",
    "    30: \"Montana\",\n",
    "    31: \"Nebraska\",\n",
    "    32: \"Nevada\",\n",
    "    33: \"New Hampshire\",\n",
    "    34: \"New Jersey\",\n",
    "    35: \"New Mexico\",\n",
    "    36: \"New York\",\n",
    "    37: \"North Carolina\",\n",
    "    38: \"North Dakota\",\n",
    "    39: \"Ohio\",\n",
    "    40: \"Oklahoma\",\n",
    "    41: \"Oregon\",\n",
    "    42: \"Pennsylvania\",\n",
    "    44: \"Rhode Island\",\n",
    "    45: \"South Carolina\",\n",
    "    46: \"South Dakota\",\n",
    "    47: \"Tennessee\",\n",
    "    48: \"Texas\",\n",
    "    49: \"Utah\",\n",
    "    50: \"Vermont\",\n",
    "    51: \"Virginia\",\n",
    "    53: \"Washington\",\n",
    "    54: \"West Virginia\",\n",
    "    55: \"Wisconsin\",\n",
    "    56: \"Wyoming\"\n",
    "}\n",
    "\n",
    "age[\"STATEFIP\"] = age[\"STATEFIP\"].replace(fips_to_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823314cc",
   "metadata": {},
   "source": [
    "##### We then filter out everything but median age, state, and year, with median age indexed against state and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98fbb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = age.rename(columns = {\"STATEFIP\": \"state\", \"YEAR\": \"year\"})\n",
    "\n",
    "med_age = age.loc[:, [\"state\", \"year\", \"med_age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f532a",
   "metadata": {},
   "source": [
    "#### Bachelor's Attainment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ff0c4",
   "metadata": {},
   "source": [
    "##### We start by converting the fips codes to state names, and then renaming the columns to match our column naming scheme for the other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e2e592e-97b8-4310-96e8-fd5984fc30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "education[\"STATEFIP\"] = education[\"STATEFIP\"].replace(fips_to_states)\n",
    "education = education.rename(columns = {\"STATEFIP\": \"state\", \"YEAR\": \"year\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9ca27",
   "metadata": {},
   "source": [
    "##### We calculate the percentage of bachelor attainment by dividing the number of people with a bachelor's education or higher by the total population. As we are missing 2024 data for bachelor attainment, we had to import a dataset for just that year, which we prepare for merging by assigning it the year 2024 as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "543e884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "education[\"bach_per\"] = education[\"bach_pop\"] / education[\"total_pop\"]\n",
    "\n",
    "bach_2024[\"year\"] = 2024\n",
    "bach_2024 = bach_2024.rename(columns = {\"State\": \"state\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45c5cd",
   "metadata": {},
   "source": [
    "##### Because the 2024 bachelor attainment is not represented as a percentage, we have to divide it by 100 so it matches our other bachelor attainment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e72f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "bach_2024[\"2024 Bachelors or Higher\"] = bach_2024[\"2024 Bachelors or Higher\"]/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d389ca",
   "metadata": {},
   "source": [
    "##### We merge education dataframe with the 2024 bachelor's attainment dataframe, and then create a new dataframe filtering out all the variables except for bachelor attainment, state and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "607b11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_merge = pd.merge(education, bach_2024, on=[\"state\", \"year\"], how=\"outer\")\n",
    "education_merge.loc[education_merge[\"year\"] == 2024, \"bach_per\"] = education_merge.loc[education_merge[\"year\"] == 2024, \"2024 Bachelors or Higher\"]\n",
    "education_merge = education_merge.drop(columns = [\"2024 Bachelors or Higher\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bc74392",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_bach = education_merge.loc[:, [\"state\", \"year\", \"bach_per\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b76159",
   "metadata": {},
   "source": [
    "#### Population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f68ee",
   "metadata": {},
   "source": [
    "##### Here, we rename some columns to match the naming scheme of our other datasets, create a new variable representing the total voting age population, and then filtering our dataframe to only include voting age population, population aged 18-24, population aged 25-44, population aged 45-64, population aged 65+, state, and year. We then remove the national level data (USA as a whole), and filter the dataset to only include election years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec764287-2b95-4866-a22c-a625f7d3bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_renamed = population.rename(columns = {\"Total Population\": \"total_pop\", \"Year\": \"year\", \"Description\": \"state\"})\n",
    "population_renamed[\"voting_age_pop\"] = population_renamed[\"Population 18-54\"] + population_renamed[\"Population 55+\"]\n",
    "population_renamed = population_renamed.loc[:, [\"state\", \"year\", \"voting_age_pop\", \"Population 18-24\", \"Population 25-44\", \"Population 45-64\", \"Population 65+\"]]\n",
    "population_renamed = population_renamed.loc[population_renamed[\"state\"] != \"U.S.\"]\n",
    "population_renamed[\"year\"] = population_renamed[\"year\"].astype(str)\n",
    "population_renamed = population_renamed[population_renamed[\"year\"].isin(election_years)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed0283",
   "metadata": {},
   "source": [
    "#### Voter Participation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78019807",
   "metadata": {},
   "source": [
    "##### Here, we melt voter participation to create a dataframe with voter participation indexed against state and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3191f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_participation_melt = pd.melt(voter_participation,\n",
    "                                   id_vars=\"State\",\n",
    "                                   value_vars=[\"2000\", \"2004\", \"2008\", \"2012\", \"2016\", \"2020\", \"2024\"],\n",
    "                                    var_name = \"year\",\n",
    "                                    value_name=\"voter_participation\").iloc[:-6].rename(columns = {\"State\": \"state\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6718c",
   "metadata": {},
   "source": [
    "### Final Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7cf74a",
   "metadata": {},
   "source": [
    "##### Here, we're merging all the different dataframes we've made together. We start by standardizing the column inputs for the charts, by converting all the year columns to integers, and capitalizing all the state columns. We then left join all the dataframes together on state and year. After creating a merged dataframe, we calculate the democratic voter percentage and Republican voter percentage by dividing the total number of the respective votes by the total votes for each state and year. Finally, we create a dummy variable that is True when the Democrats won a state, and False if the Republicans won instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "570d87c3-b5f3-41b7-a0e2-6eea9f32c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_melted[\"year\"] = unemployment_melted[\"year\"].astype(int)\n",
    "unemployment_melted[\"state\"] = unemployment_melted[\"state\"].str.upper()\n",
    "med_income_melted[\"year\"] = med_income_melted[\"year\"].astype(int)\n",
    "med_income_melted[\"state\"] = med_income_melted[\"state\"].str.upper()\n",
    "med_age[\"state\"] = med_age[\"state\"].str.upper()\n",
    "edu_bach[\"state\"] = edu_bach[\"state\"].str.upper()\n",
    "population_renamed[\"state\"] = population_renamed[\"state\"].str.upper()\n",
    "population_renamed[\"year\"] = population_renamed[\"year\"].astype(int)\n",
    "voter_participation_melt[\"year\"] = voter_participation_melt[\"year\"].astype(int)\n",
    "voter_participation_melt[\"state\"] = voter_participation_melt[\"state\"].str.upper()\n",
    "\n",
    "merge1 = pd.merge(totalvotes_melted, demvotes_melted, on=[\"state\", \"year\"], how=\"left\")\n",
    "merge2 = pd.merge(merge1, repvotes_melted, on=[\"state\", \"year\"], how=\"left\")\n",
    "merge3 = pd.merge(merge2, unemployment_melted, on=[\"state\", \"year\"], how=\"left\")\n",
    "merge4 = pd.merge(merge3, med_income_melted, on=[\"state\", \"year\"], how=\"left\")\n",
    "merge5 = pd.merge(merge4, med_age, on=[\"state\", \"year\"], how=\"left\")\n",
    "merge6 = pd.merge(merge5, edu_bach, on=[\"state\", \"year\"], how=\"left\")\n",
    "merge7 = pd.merge(merge6, voter_participation_melt, on=[\"state\", \"year\"], how=\"left\")\n",
    "merged_data = pd.merge(merge7, population_renamed, on=[\"state\", \"year\"], how=\"left\")\n",
    "\n",
    "merged_data[\"dem_votes_per\"] = merged_data[\"dem_votes\"] / merged_data[\"total_votes\"]\n",
    "merged_data[\"rep_votes_per\"] = merged_data[\"rep_votes\"] / merged_data[\"total_votes\"]\n",
    "\n",
    "merged_data[\"dem_win\"] = merged_data[\"dem_votes_per\"] > merged_data[\"rep_votes_per\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545829e4",
   "metadata": {},
   "source": [
    "#### Exporting Cleaned CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1a018",
   "metadata": {},
   "source": [
    "##### The final step is to create an export path for the cleaned csv, and export it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afc6a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_path = \"/Users/jamil/Coding/election_results/data/Voting_Breakdown_By_Socioeconomic_and_Demographic_Factors.csv\"\n",
    "\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "merged_data.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
